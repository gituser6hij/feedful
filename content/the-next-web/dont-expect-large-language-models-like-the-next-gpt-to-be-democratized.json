{
  "title": "Don’t expect large language models like the next GPT to be democratized",
  "url": "https://thenextweb.com/news/dont-expect-large-language-models-like-the-next-gpt-to-be-democratized",
  "date": "Sat, 21 May 2022 16:00:29 +0000",
  "content": "<img src=\"https://img-cdn.tnwcdn.com/image?fit=796%2C417&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2022%2F05%2Flearning-language-models-hed.jpg&signature=9776d4342f87959960d6a34934da60d3\" width=\"796\" height=\"417\"><br />This article is part of our coverage of the latest in AI research. In early May, Meta released Open Pretrained Transformer (OPT-175B), a large language model (LLM) that can perform various tasks. Large language models have become one of the hottest areas of research in artificial intelligence in the past few years. OPT-175B is the latest entrant in the LLM arms race triggered by OpenAI’s GPT-3, a deep neural network with 175 billion parameters. GPT-3 showed that LLMs can perform many tasks without undergoing extra training and only seeing a few examples (zero- or few-shot learning). Microsoft later integrated GPT-3 into several of&#8230;<br /><br /><a href=\"https://thenextweb.com/news/dont-expect-large-language-models-like-the-next-gpt-to-be-democratized?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed\">This story continues</a> at The Next Web",
  "image": "https://img-cdn.tnwcdn.com/image/neural?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2022%2F05%2Flearning-language-models-hed.jpg&signature=7aff3dd351694d1e80e1e2cb91c17a04",
  "description": "Large language models like GPT-3 and OPT-17B are expensive to build and train, and give their creators a competitive advantage.",
  "publisher": "The Next Web",
  "publisherUrl": "https://thenextweb.com/"
}